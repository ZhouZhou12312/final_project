{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fe61611-3e72-4b4e-b195-3065c668b0d2",
   "metadata": {},
   "source": [
    "# Resume Filter Project GPT2.0 Version\n",
    "\n",
    "### Author: \n",
    "Pengyu Tao pt2649, Zhou Zhou zz3237\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bc30604-b0ec-450b-a19d-1a39c652afb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.13.2\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "print(platform. python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a25a8b7-2983-4557-8f5f-99165d33acff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==0.28\n",
      "  Using cached openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\rick\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai==0.28) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rick\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai==0.28) (4.67.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\rick\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai==0.28) (3.11.13)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rick\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.20->openai==0.28) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rick\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.20->openai==0.28) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rick\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.20->openai==0.28) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rick\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.20->openai==0.28) (2025.1.31)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\rick\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp->openai==0.28) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\rick\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp->openai==0.28) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\rick\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp->openai==0.28) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\rick\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp->openai==0.28) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\rick\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp->openai==0.28) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\rick\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp->openai==0.28) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\rick\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp->openai==0.28) (1.18.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\rick\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm->openai==0.28) (0.4.6)\n",
      "Using cached openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.78.1\n",
      "    Uninstalling openai-1.78.1:\n",
      "      Successfully uninstalled openai-1.78.1\n",
      "Successfully installed openai-0.28.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~upyterlab (C:\\Users\\Rick\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~upyterlab (C:\\Users\\Rick\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~upyterlab (C:\\Users\\Rick\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-openai 0.3.13 requires openai<2.0.0,>=1.68.2, but you have openai 0.28.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==0.28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e46d82d-5e1d-4c3a-8511-383fc33c6687",
   "metadata": {},
   "source": [
    "### Some important notes here: the headlines begin with \"steps\" are required for user interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecdfa9f-e7d5-4709-bcbd-7f01fe4e2a28",
   "metadata": {},
   "source": [
    "# 1. Environment Setup and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf540c2e-2c7c-426c-8324-1b1a366f308e",
   "metadata": {},
   "source": [
    "So for this project, we need you to go to https://www.kaggle.com/datasets/saugataroyarghya/resume-dataset to download the dataset in this same file directory for ai training purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b35b3a-5170-48f1-89a6-b3b9cfbba551",
   "metadata": {},
   "source": [
    "### All imports required for this whole notebook, if you don't have it then use pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8599c608-5835-4933-853f-4e795d5fe4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import glob\n",
    "import pandas as pd\n",
    "import sys\n",
    "import openai\n",
    "import time\n",
    "import faiss\n",
    "import numpy as np\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "import torch\n",
    "from transformers import Trainer, TrainingArguments, GPT2Tokenizer, GPT2LMHeadModel\n",
    "from datasets import load_dataset\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Optional dependencies for PDF/DOCX parsing\n",
    "try:\n",
    "    import PyPDF2\n",
    "except ImportError:\n",
    "    PyPDF2 = None\n",
    "\n",
    "try:\n",
    "    import docx\n",
    "except ImportError:\n",
    "    docx = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ec8a8a-904f-4a05-ac54-8efc7a6d3728",
   "metadata": {},
   "source": [
    "# 2. Data Collection and Preprocessing\n",
    "   - Cleaning the resume data that the user uploads\n",
    "   - Data cleaning: Handling missing values, text preprocessing, and data labeling\n",
    "   - Save processed data to data/processed/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a3c7e9b-8dec-45d3-84c3-251419a2c650",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessor:\n",
    "    \"\"\"\n",
    "    DataPreprocessor handles loading raw resumes in multiple formats,\n",
    "    cleaning text, extracting structured sections, and saving processed output.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dir: str, output_dir: str):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_dir: Directory path to scan by default or empty to prompt for paths\n",
    "            output_dir: Directory where processed JSON will be written.\n",
    "        \"\"\"\n",
    "        self.input_dir = input_dir\n",
    "        self.output_dir = output_dir\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "\n",
    "    def _collect_paths(self, default_dir: str) -> list:\n",
    "        \"\"\"\n",
    "        Collect resume file paths from default_dir or via user input.\n",
    "        Accepts CSV, PDF, DOCX, TXT. If input is not a valid path, performs a fuzzy search\n",
    "        in the current working directory for matching filenames.\n",
    "        \"\"\"\n",
    "        paths = []\n",
    "        # 1) Scan default directory if it exists\n",
    "        if os.path.isdir(default_dir):\n",
    "            for ext in (\"*.csv\", \"*.pdf\", \"*.docx\", \"*.txt\"):\n",
    "                paths.extend(glob.glob(os.path.join(default_dir, ext)))\n",
    "        # 2) If still no files, prompt user with instructions\n",
    "        if not paths:\n",
    "            print(f\"No resume files found in '{default_dir}'.\")\n",
    "            print(\"Please enter either:\")\n",
    "            print(\"  • An absolute or relative file path (e.g. C:\\\\Users\\\\Rick\\\\Desktop\\\\resume.pdf or ~/resumes/resume.pdf)\")\n",
    "            print(\"  • A filename to fuzzy-search your workspace (e.g. 'resume.pdf')\")\n",
    "            user_input = input(\"Enter directory path, file path, or filename: \")\n",
    "            entries = [e.strip().strip('\"\\'') for e in user_input.split(',') if e.strip()]\n",
    "            for entry in entries:\n",
    "                entry_path = os.path.abspath(os.path.expanduser(entry))\n",
    "                if os.path.isdir(entry_path):\n",
    "                    for ext in (\"*.csv\", \"*.pdf\", \"*.docx\", \"*.txt\"):\n",
    "                        paths.extend(glob.glob(os.path.join(entry_path, ext)))\n",
    "                elif os.path.isfile(entry_path):\n",
    "                    paths.append(entry_path)\n",
    "                else:\n",
    "                    fuzzy = glob.glob(f\"**/{entry}\", recursive=True)\n",
    "                    if fuzzy:\n",
    "                        print(f\"Fuzzy match found for '{entry}': {fuzzy}\")\n",
    "                        paths.extend([os.path.abspath(p) for p in fuzzy])\n",
    "                    else:\n",
    "                        print(f\"Warning: '{entry}' not found or matched. Skipping.\")\n",
    "        return paths\n",
    "\n",
    "    def load_resumes(self) -> list:\n",
    "        \"\"\"\n",
    "        Load resumes from collected paths.\n",
    "        Returns a list of dicts: {'id': str, 'raw_text': str}.\n",
    "        \"\"\"\n",
    "        paths = self._collect_paths(self.input_dir)\n",
    "        if not paths:\n",
    "            raise RuntimeError(\"No valid resume file paths provided. Aborting.\")\n",
    "\n",
    "        records = []\n",
    "        for path in paths:\n",
    "            ext = os.path.splitext(path)[1].lower()\n",
    "            basename = os.path.basename(path)\n",
    "            try:\n",
    "                if ext == \".csv\":\n",
    "                    df = pd.read_csv(path)\n",
    "                    if \"resume_text\" not in df.columns:\n",
    "                        raise ValueError(f\"CSV '{basename}' is missing the 'resume_text' column.\")\n",
    "                    for idx, row in df.iterrows():\n",
    "                        records.append({\n",
    "                            'id': row.get('id', f\"{basename}_{idx}\"),\n",
    "                            'raw_text': str(row['resume_text'])\n",
    "                        })\n",
    "                elif ext == \".pdf\":\n",
    "                    if PyPDF2 is None:\n",
    "                        print(f\"Warning: PyPDF2 not installed; skipping PDF file '{basename}'.\")\n",
    "                        continue\n",
    "                    text_pages = []\n",
    "                    with open(path, \"rb\") as f:\n",
    "                        reader = PyPDF2.PdfReader(f)\n",
    "                        for page in reader.pages:\n",
    "                            text_pages.append(page.extract_text() or '')\n",
    "                    records.append({'id': basename, 'raw_text': '\\n'.join(text_pages)})\n",
    "                elif ext == \".docx\":\n",
    "                    if docx is None:\n",
    "                        print(f\"Warning: python-docx not installed; skipping DOCX file '{basename}'.\")\n",
    "                        continue\n",
    "                    document = docx.Document(path)\n",
    "                    paragraphs = [p.text for p in document.paragraphs]\n",
    "                    records.append({'id': basename, 'raw_text': '\\n'.join(paragraphs)})\n",
    "                elif ext == \".txt\":\n",
    "                    with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                        records.append({'id': basename, 'raw_text': f.read()})\n",
    "                else:\n",
    "                    print(f\"Skipping unsupported file type: {basename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing '{basename}': {e}\")\n",
    "        return records\n",
    "\n",
    "    def clean_text(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Normalize text:\n",
    "          - lowercase\n",
    "          - remove non-ASCII characters\n",
    "          - collapse whitespace\n",
    "        \"\"\"\n",
    "        text = text.lower()\n",
    "        text = re.sub(r\"[^\\x00-\\x7f]\", \"\", text)\n",
    "        text = re.sub(r\"\\s+\", \" \", text)\n",
    "        return text.strip()\n",
    "\n",
    "    def extract_sections(self, text: str) -> dict:\n",
    "        \"\"\"\n",
    "        Placeholder for splitting text into sections like 'education', 'experience'.\n",
    "        TODO: implement via regex or NLP-based heading detection.\n",
    "        \"\"\"\n",
    "        return {}\n",
    "\n",
    "    def process(self):\n",
    "        \"\"\"\n",
    "        Full pipeline:\n",
    "          1) Load resumes\n",
    "          2) Clean text\n",
    "          3) Extract sections\n",
    "          4) Save processed data as JSON\n",
    "        \"\"\"\n",
    "        records = self.load_resumes()\n",
    "        processed = []\n",
    "        for rec in records:\n",
    "            clean = self.clean_text(rec['raw_text'])\n",
    "            sections = self.extract_sections(clean)\n",
    "            entry = {'id': rec['id'], 'clean_text': clean, **sections}\n",
    "            processed.append(entry)\n",
    "\n",
    "        out_path = os.path.join(self.output_dir, 'processed_resumes.json')\n",
    "        with open(out_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(processed, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"Processed {len(processed)} resumes → {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c6795a-dbed-48a9-b947-31c466910c67",
   "metadata": {},
   "source": [
    "## Step1: Ask User to upload their Resume using required file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "987ca510-e44e-4496-a99a-0c54244f8af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No resume files found in 'data/raw'.\n",
      "Please enter either:\n",
      "  • An absolute or relative file path (e.g. C:\\Users\\Rick\\Desktop\\resume.pdf or ~/resumes/resume.pdf)\n",
      "  • A filename to fuzzy-search your workspace (e.g. 'resume.pdf')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter directory path, file path, or filename:  \"C:\\Users\\Rick\\Desktop\\5293\\final project notebook running check\\Jack_TotallyUnqualified_Resume.pdf\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1 resumes → data/processed\\processed_resumes.json\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    input_dir = 'data/raw'\n",
    "    output_dir = 'data/processed'\n",
    "    dp = DataPreprocessor(input_dir, output_dir)\n",
    "    dp.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56556834-07f2-4c54-a008-ad070174885f",
   "metadata": {},
   "source": [
    "## Step2: Ask User to enter their own Api Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "576b60cf-6350-405b-89f9-16e010773c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: This pipeline currently uses OpenAI. Please enter your OpenAI API key.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "API key:  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\n"
     ]
    }
   ],
   "source": [
    "print(\"Note: This pipeline currently uses OpenAI. Please enter your OpenAI API key.\")\n",
    "api_key = input(\"API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "278406bc-b4ea-47e3-8bbd-5bade6358131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input job description\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "def load_job_description(source: str) -> str:\n",
    "    \"\"\"\n",
    "    Load job description text from a local file (.txt|.pdf|.docx) or URL.\n",
    "    Performs fuzzy substring search if the direct path fails.\n",
    "    \"\"\"\n",
    "    source = source.strip().strip('\"\\'')\n",
    "\n",
    "    if source.startswith(('http://', 'https://')):\n",
    "        import requests\n",
    "        r = requests.get(source)\n",
    "        r.raise_for_status()\n",
    "        return r.text\n",
    "\n",
    "    path = os.path.abspath(os.path.expanduser(source))\n",
    "    if os.path.isfile(path):\n",
    "        ext = os.path.splitext(path)[1].lower()\n",
    "        if ext == '.txt':\n",
    "            with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                return f.read()\n",
    "        elif ext == '.pdf':\n",
    "            from PyPDF2 import PdfReader\n",
    "            reader = PdfReader(path)\n",
    "            return \"\\n\".join([page.extract_text() or '' for page in reader.pages])\n",
    "        elif ext == '.docx':\n",
    "            import docx\n",
    "            doc = docx.Document(path)\n",
    "            return \"\\n\".join([p.text for p in doc.paragraphs])\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported extension: {ext}\")\n",
    "    # Fuzzy search\n",
    "    name = os.path.basename(source)\n",
    "    print(f\"'{source}' not found; fuzzy searching for '*{name}*'...\")\n",
    "    matches = glob.glob(f\"**/*{name}*\", recursive=True)\n",
    "    if matches:\n",
    "        print(f\"Found: {matches[0]}\")\n",
    "        return load_job_description(matches[0])\n",
    "    raise FileNotFoundError(f\"Source '{source}' not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb6a791-43b4-4070-93bc-f96e9ce0a55c",
   "metadata": {},
   "source": [
    "## Step3: Ask User to put their own job description with required format needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "875cafde-c6ce-4dd4-82db-4aecc956e843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter job description (.txt/.pdf/.docx path or URL):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \"C:\\Users\\Rick\\Desktop\\5293\\final project notebook running check\\sample-job-description.pdf\"\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEnter job description (.txt/.pdf/.docx path):\")\n",
    "src = input()\n",
    "job_description = load_job_description(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31246349-ab6a-49ca-9d82-52bd57485ea3",
   "metadata": {},
   "source": [
    "# 3. Model Selection and Training\n",
    "   - Choose model architecture: GPT-2.0 via OpenAI API\n",
    "   - Fine-tune the model using resume and job description data from Kaggle datasets\n",
    "   - Implement prompt optimization strategies to refine output quality\n",
    "   - Save the trained model to models/fine_tuned_llm.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6645bbf-6664-4d2a-be31-7a07e3057276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import openai\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0be07e28-7afa-4013-b34b-06c7ad05d8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key is working and embedding generated successfully.\n"
     ]
    }
   ],
   "source": [
    "openai.api_key = api_key\n",
    "try:\n",
    "    response = openai.Embedding.create(\n",
    "        input=[\"Test embedding\"],\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    print(\"API Key is working and embedding generated successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"API Key Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06abbe60-c66e-411f-b761-b20bacf668af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting async embedding generation...\n",
      "Processed 20/9544 | Elapsed: 4.10s | Remaining: 1953.44s\n",
      "Processed 40/9544 | Elapsed: 6.35s | Remaining: 1508.05s\n",
      "Processed 60/9544 | Elapsed: 6.81s | Remaining: 1076.32s\n",
      "Processed 80/9544 | Elapsed: 7.22s | Remaining: 854.31s\n",
      "Processed 100/9544 | Elapsed: 8.07s | Remaining: 762.54s\n",
      "Processed 120/9544 | Elapsed: 8.88s | Remaining: 697.74s\n",
      "Processed 140/9544 | Elapsed: 9.31s | Remaining: 625.40s\n",
      "Processed 160/9544 | Elapsed: 11.24s | Remaining: 659.44s\n",
      "Processed 180/9544 | Elapsed: 11.80s | Remaining: 613.68s\n",
      "Processed 200/9544 | Elapsed: 12.35s | Remaining: 576.89s\n",
      "Processed 220/9544 | Elapsed: 12.92s | Remaining: 547.47s\n",
      "Processed 240/9544 | Elapsed: 13.36s | Remaining: 518.11s\n",
      "Processed 260/9544 | Elapsed: 13.81s | Remaining: 493.07s\n",
      "Processed 280/9544 | Elapsed: 14.31s | Remaining: 473.33s\n",
      "Processed 300/9544 | Elapsed: 14.73s | Remaining: 453.82s\n",
      "Processed 320/9544 | Elapsed: 17.16s | Remaining: 494.65s\n",
      "Processed 340/9544 | Elapsed: 17.64s | Remaining: 477.61s\n",
      "Processed 360/9544 | Elapsed: 18.34s | Remaining: 467.88s\n",
      "Processed 380/9544 | Elapsed: 18.87s | Remaining: 455.01s\n",
      "Processed 400/9544 | Elapsed: 19.38s | Remaining: 442.98s\n",
      "Processed 420/9544 | Elapsed: 19.81s | Remaining: 430.33s\n",
      "Processed 440/9544 | Elapsed: 20.29s | Remaining: 419.76s\n",
      "Processed 460/9544 | Elapsed: 20.73s | Remaining: 409.30s\n",
      "Processed 480/9544 | Elapsed: 21.69s | Remaining: 409.51s\n",
      "Processed 500/9544 | Elapsed: 22.10s | Remaining: 399.79s\n",
      "Processed 520/9544 | Elapsed: 23.48s | Remaining: 407.50s\n",
      "Processed 540/9544 | Elapsed: 23.91s | Remaining: 398.62s\n",
      "Processed 560/9544 | Elapsed: 24.44s | Remaining: 392.12s\n",
      "Processed 580/9544 | Elapsed: 24.87s | Remaining: 384.35s\n",
      "Processed 600/9544 | Elapsed: 25.30s | Remaining: 377.07s\n",
      "Processed 620/9544 | Elapsed: 26.07s | Remaining: 375.25s\n",
      "Processed 640/9544 | Elapsed: 26.51s | Remaining: 368.81s\n",
      "Processed 660/9544 | Elapsed: 26.93s | Remaining: 362.48s\n",
      "Processed 680/9544 | Elapsed: 28.97s | Remaining: 377.58s\n",
      "Processed 700/9544 | Elapsed: 29.52s | Remaining: 372.95s\n",
      "Processed 720/9544 | Elapsed: 29.93s | Remaining: 366.82s\n",
      "Processed 740/9544 | Elapsed: 30.32s | Remaining: 360.75s\n",
      "Processed 760/9544 | Elapsed: 30.74s | Remaining: 355.33s\n",
      "Processed 780/9544 | Elapsed: 31.18s | Remaining: 350.35s\n",
      "Processed 800/9544 | Elapsed: 31.69s | Remaining: 346.38s\n",
      "Processed 820/9544 | Elapsed: 32.11s | Remaining: 341.67s\n",
      "Processed 840/9544 | Elapsed: 32.68s | Remaining: 338.60s\n",
      "Processed 860/9544 | Elapsed: 33.09s | Remaining: 334.13s\n",
      "Processed 880/9544 | Elapsed: 33.53s | Remaining: 330.15s\n",
      "Processed 900/9544 | Elapsed: 34.95s | Remaining: 335.71s\n",
      "Processed 920/9544 | Elapsed: 35.79s | Remaining: 335.50s\n",
      "Processed 940/9544 | Elapsed: 36.20s | Remaining: 331.38s\n",
      "Processed 960/9544 | Elapsed: 36.77s | Remaining: 328.83s\n",
      "Processed 980/9544 | Elapsed: 37.33s | Remaining: 326.25s\n",
      "Processed 1000/9544 | Elapsed: 37.75s | Remaining: 322.50s\n",
      "Processed 1020/9544 | Elapsed: 38.32s | Remaining: 320.24s\n",
      "Processed 1040/9544 | Elapsed: 38.79s | Remaining: 317.18s\n",
      "Processed 1060/9544 | Elapsed: 39.20s | Remaining: 313.72s\n",
      "Processed 1080/9544 | Elapsed: 39.78s | Remaining: 311.77s\n",
      "Processed 1100/9544 | Elapsed: 40.45s | Remaining: 310.51s\n",
      "Processed 1120/9544 | Elapsed: 41.24s | Remaining: 310.15s\n",
      "Processed 1140/9544 | Elapsed: 41.71s | Remaining: 307.49s\n",
      "Processed 1160/9544 | Elapsed: 42.13s | Remaining: 304.48s\n",
      "Processed 1180/9544 | Elapsed: 43.82s | Remaining: 310.57s\n",
      "Processed 1200/9544 | Elapsed: 44.27s | Remaining: 307.85s\n",
      "Processed 1220/9544 | Elapsed: 44.69s | Remaining: 304.94s\n",
      "Processed 1240/9544 | Elapsed: 45.11s | Remaining: 302.09s\n",
      "Processed 1260/9544 | Elapsed: 45.66s | Remaining: 300.19s\n",
      "Error 504: <!DOCTYPE html>\n",
      "<!--[if lt IE 7]> <html class=\"no-js ie6 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if IE 7]>    <html class=\"no-js ie7 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if IE 8]>    <html class=\"no-js ie8 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if gt IE 8]><!--> <html class=\"no-js\" lang=\"en-US\"> <!--<![endif]-->\n",
      "<head>\n",
      "\n",
      "\n",
      "<title>api.openai.com | 504: Gateway time-out</title>\n",
      "<meta charset=\"UTF-8\" />\n",
      "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" />\n",
      "<meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\" />\n",
      "<meta name=\"robots\" content=\"noindex, nofollow\" />\n",
      "<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" />\n",
      "<link rel=\"stylesheet\" id=\"cf_styles-css\" href=\"/cdn-cgi/styles/main.css\" />\n",
      "\n",
      "\n",
      "</head>\n",
      "<body>\n",
      "<div id=\"cf-wrapper\">\n",
      "    <div id=\"cf-error-details\" class=\"p-0\">\n",
      "        <header class=\"mx-auto pt-10 lg:pt-6 lg:px-8 w-240 lg:w-full mb-8\">\n",
      "            <h1 class=\"inline-block sm:block sm:mb-2 font-light text-60 lg:text-4xl text-black-dark leading-tight mr-2\">\n",
      "              <span class=\"inline-block\">Gateway time-out</span>\n",
      "              <span class=\"code-label\">Error code 504</span>\n",
      "            </h1>\n",
      "            <div>\n",
      "               Visit <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_504&utm_campaign=api.openai.com\" target=\"_blank\" rel=\"noopener noreferrer\">cloudflare.com</a> for more information.\n",
      "            </div>\n",
      "            <div class=\"mt-3\">2025-05-14 05:35:04 UTC</div>\n",
      "        </header>\n",
      "        <div class=\"my-8 bg-gradient-gray\">\n",
      "            <div class=\"w-240 lg:w-full mx-auto\">\n",
      "                <div class=\"clearfix md:px-8\">\n",
      "                  \n",
      "<div id=\"cf-browser-status\" class=\" relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\n",
      "  <div class=\"relative mb-10 md:m-0\">\n",
      "    \n",
      "    <span class=\"cf-icon-browser block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
      "    <span class=\"cf-icon-ok w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
      "    \n",
      "  </div>\n",
      "  <span class=\"md:block w-full truncate\">You</span>\n",
      "  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
      "    \n",
      "    Browser\n",
      "    \n",
      "  </h3>\n",
      "  <span class=\"leading-1.3 text-2xl text-green-success\">Working</span>\n",
      "</div>\n",
      "\n",
      "<div id=\"cf-cloudflare-status\" class=\" relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\n",
      "  <div class=\"relative mb-10 md:m-0\">\n",
      "    <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_504&utm_campaign=api.openai.com\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
      "    <span class=\"cf-icon-cloud block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
      "    <span class=\"cf-icon-ok w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
      "    </a>\n",
      "  </div>\n",
      "  <span class=\"md:block w-full truncate\">Newark</span>\n",
      "  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
      "    <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_504&utm_campaign=api.openai.com\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
      "    Cloudflare\n",
      "    </a>\n",
      "  </h3>\n",
      "  <span class=\"leading-1.3 text-2xl text-green-success\">Working</span>\n",
      "</div>\n",
      "\n",
      "<div id=\"cf-host-status\" class=\"cf-error-source relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\n",
      "  <div class=\"relative mb-10 md:m-0\">\n",
      "    \n",
      "    <span class=\"cf-icon-server block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
      "    <span class=\"cf-icon-error w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
      "    \n",
      "  </div>\n",
      "  <span class=\"md:block w-full truncate\">api.openai.com</span>\n",
      "  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
      "    \n",
      "    Host\n",
      "    \n",
      "  </h3>\n",
      "  <span class=\"leading-1.3 text-2xl text-red-error\">Error</span>\n",
      "</div>\n",
      "\n",
      "                </div>\n",
      "            </div>\n",
      "        </div>\n",
      "\n",
      "        <div class=\"w-240 lg:w-full mx-auto mb-8 lg:px-8\">\n",
      "            <div class=\"clearfix\">\n",
      "                <div class=\"w-1/2 md:w-full float-left pr-6 md:pb-10 md:pr-0 leading-relaxed\">\n",
      "                    <h2 class=\"text-3xl font-normal leading-1.3 mb-4\">What happened?</h2>\n",
      "                    <p>The web server reported a gateway time-out error.</p>\n",
      "                </div>\n",
      "                <div class=\"w-1/2 md:w-full float-left leading-relaxed\">\n",
      "                    <h2 class=\"text-3xl font-normal leading-1.3 mb-4\">What can I do?</h2>\n",
      "                    <p class=\"mb-6\">Please try again in a few minutes.</p>\n",
      "                </div>\n",
      "            </div>\n",
      "        </div>\n",
      "\n",
      "        <div class=\"cf-error-footer cf-wrapper w-240 lg:w-full py-10 sm:py-4 sm:px-8 mx-auto text-center sm:text-left border-solid border-0 border-t border-gray-300\">\n",
      "  <p class=\"text-13\">\n",
      "    <span class=\"cf-footer-item sm:block sm:mb-1\">Cloudflare Ray ID: <strong class=\"font-semibold\">93f800610d725e39</strong></span>\n",
      "    <span class=\"cf-footer-separator sm:hidden\">&bull;</span>\n",
      "    <span id=\"cf-footer-item-ip\" class=\"cf-footer-item hidden sm:block sm:mb-1\">\n",
      "      Your IP:\n",
      "      <button type=\"button\" id=\"cf-footer-ip-reveal\" class=\"cf-footer-ip-reveal-btn\">Click to reveal</button>\n",
      "      <span class=\"hidden\" id=\"cf-footer-ip\">47.230.103.5</span>\n",
      "      <span class=\"cf-footer-separator sm:hidden\">&bull;</span>\n",
      "    </span>\n",
      "    <span class=\"cf-footer-item sm:block sm:mb-1\"><span>Performance &amp; security by</span> <a rel=\"noopener noreferrer\" href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_504&utm_campaign=api.openai.com\" id=\"brand_link\" target=\"_blank\">Cloudflare</a></span>\n",
      "    \n",
      "  </p>\n",
      "  <script>(function(){function d(){var b=a.getElementById(\"cf-footer-item-ip\"),c=a.getElementById(\"cf-footer-ip-reveal\");b&&\"classList\"in b&&(b.classList.remove(\"hidden\"),c.addEventListener(\"click\",function(){c.classList.add(\"hidden\");a.getElementById(\"cf-footer-ip\").classList.remove(\"hidden\")}))}var a=document;document.addEventListener&&a.addEventListener(\"DOMContentLoaded\",d)})();</script>\n",
      "</div><!-- /.error-footer -->\n",
      "\n",
      "\n",
      "    </div>\n",
      "</div>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "Processed 1280/9544 | Elapsed: 345.79s | Remaining: 2232.49s\n",
      "Processed 1300/9544 | Elapsed: 346.45s | Remaining: 2197.04s\n",
      "Processed 1320/9544 | Elapsed: 347.23s | Remaining: 2163.37s\n",
      "Processed 1340/9544 | Elapsed: 347.80s | Remaining: 2129.34s\n",
      "Processed 1360/9544 | Elapsed: 348.40s | Remaining: 2096.55s\n",
      "Processed 1380/9544 | Elapsed: 348.81s | Remaining: 2063.53s\n",
      "Processed 1400/9544 | Elapsed: 349.42s | Remaining: 2032.64s\n",
      "Processed 1420/9544 | Elapsed: 349.99s | Remaining: 2002.32s\n",
      "Processed 1440/9544 | Elapsed: 350.42s | Remaining: 1972.08s\n",
      "Processed 1460/9544 | Elapsed: 350.87s | Remaining: 1942.78s\n",
      "Processed 1480/9544 | Elapsed: 351.39s | Remaining: 1914.62s\n",
      "Processed 1500/9544 | Elapsed: 351.82s | Remaining: 1886.70s\n",
      "Processed 1520/9544 | Elapsed: 352.27s | Remaining: 1859.59s\n",
      "Processed 1540/9544 | Elapsed: 352.72s | Remaining: 1833.20s\n",
      "Processed 1560/9544 | Elapsed: 353.33s | Remaining: 1808.31s\n",
      "Processed 1580/9544 | Elapsed: 353.72s | Remaining: 1782.90s\n",
      "Processed 1600/9544 | Elapsed: 354.48s | Remaining: 1759.97s\n",
      "Processed 1620/9544 | Elapsed: 354.88s | Remaining: 1735.83s\n",
      "Processed 1640/9544 | Elapsed: 355.51s | Remaining: 1713.40s\n",
      "Processed 1660/9544 | Elapsed: 356.35s | Remaining: 1692.44s\n",
      "Processed 1680/9544 | Elapsed: 356.96s | Remaining: 1670.92s\n",
      "Processed 1700/9544 | Elapsed: 357.47s | Remaining: 1649.41s\n",
      "Processed 1720/9544 | Elapsed: 357.88s | Remaining: 1627.92s\n",
      "Processed 1740/9544 | Elapsed: 358.29s | Remaining: 1606.94s\n",
      "Processed 1760/9544 | Elapsed: 358.82s | Remaining: 1586.96s\n",
      "Processed 1780/9544 | Elapsed: 359.25s | Remaining: 1566.98s\n",
      "Processed 1800/9544 | Elapsed: 359.80s | Remaining: 1547.95s\n",
      "Processed 1820/9544 | Elapsed: 360.49s | Remaining: 1529.91s\n",
      "Processed 1840/9544 | Elapsed: 361.08s | Remaining: 1511.81s\n",
      "Processed 1860/9544 | Elapsed: 361.67s | Remaining: 1494.14s\n",
      "Embedding Error: \n",
      "Processed 1880/9544 | Elapsed: 661.84s | Remaining: 2698.07s\n",
      "Processed 1900/9544 | Elapsed: 662.68s | Remaining: 2666.06s\n",
      "Processed 1920/9544 | Elapsed: 670.16s | Remaining: 2661.11s\n",
      "Processed 1940/9544 | Elapsed: 670.61s | Remaining: 2628.50s\n",
      "Processed 1960/9544 | Elapsed: 671.14s | Remaining: 2596.91s\n",
      "Processed 1980/9544 | Elapsed: 671.68s | Remaining: 2565.96s\n",
      "Processed 2000/9544 | Elapsed: 672.14s | Remaining: 2535.33s\n",
      "Processed 2020/9544 | Elapsed: 672.73s | Remaining: 2505.74s\n",
      "Processed 2040/9544 | Elapsed: 673.16s | Remaining: 2476.17s\n",
      "Processed 2060/9544 | Elapsed: 673.72s | Remaining: 2447.63s\n",
      "Processed 2080/9544 | Elapsed: 674.13s | Remaining: 2419.08s\n",
      "Processed 2100/9544 | Elapsed: 674.87s | Remaining: 2392.24s\n",
      "Processed 2120/9544 | Elapsed: 675.28s | Remaining: 2364.75s\n",
      "Processed 2140/9544 | Elapsed: 675.69s | Remaining: 2337.75s\n",
      "Processed 2160/9544 | Elapsed: 676.09s | Remaining: 2311.24s\n",
      "Processed 2180/9544 | Elapsed: 676.80s | Remaining: 2286.22s\n",
      "Processed 2200/9544 | Elapsed: 677.20s | Remaining: 2260.63s\n",
      "Processed 2220/9544 | Elapsed: 677.65s | Remaining: 2235.63s\n",
      "Processed 2240/9544 | Elapsed: 678.09s | Remaining: 2211.07s\n",
      "Processed 2260/9544 | Elapsed: 678.43s | Remaining: 2186.57s\n",
      "Processed 2280/9544 | Elapsed: 680.12s | Remaining: 2166.85s\n",
      "Processed 2300/9544 | Elapsed: 680.62s | Remaining: 2143.66s\n",
      "Processed 2320/9544 | Elapsed: 681.13s | Remaining: 2120.89s\n",
      "Processed 2340/9544 | Elapsed: 682.00s | Remaining: 2099.64s\n",
      "Processed 2360/9544 | Elapsed: 682.44s | Remaining: 2077.38s\n",
      "Processed 2380/9544 | Elapsed: 689.70s | Remaining: 2076.06s\n",
      "Processed 2400/9544 | Elapsed: 690.17s | Remaining: 2054.42s\n",
      "Processed 2420/9544 | Elapsed: 691.23s | Remaining: 2034.85s\n",
      "Processed 2440/9544 | Elapsed: 691.68s | Remaining: 2013.80s\n",
      "Processed 2460/9544 | Elapsed: 692.09s | Remaining: 1992.98s\n",
      "Processed 2480/9544 | Elapsed: 692.61s | Remaining: 1972.82s\n",
      "Processed 2500/9544 | Elapsed: 693.08s | Remaining: 1952.81s\n",
      "Processed 2520/9544 | Elapsed: 693.65s | Remaining: 1933.42s\n",
      "Processed 2540/9544 | Elapsed: 694.12s | Remaining: 1914.02s\n",
      "Processed 2560/9544 | Elapsed: 694.57s | Remaining: 1894.89s\n",
      "Processed 2580/9544 | Elapsed: 695.01s | Remaining: 1875.98s\n",
      "Processed 2600/9544 | Elapsed: 695.56s | Remaining: 1857.67s\n",
      "Processed 2620/9544 | Elapsed: 696.00s | Remaining: 1839.34s\n",
      "Processed 2640/9544 | Elapsed: 703.87s | Remaining: 1840.72s\n",
      "Processed 2660/9544 | Elapsed: 704.34s | Remaining: 1822.81s\n",
      "Processed 2680/9544 | Elapsed: 704.91s | Remaining: 1805.40s\n",
      "Processed 2700/9544 | Elapsed: 711.94s | Remaining: 1804.65s\n",
      "Processed 2720/9544 | Elapsed: 712.47s | Remaining: 1787.46s\n",
      "Processed 2740/9544 | Elapsed: 713.18s | Remaining: 1770.98s\n",
      "Processed 2760/9544 | Elapsed: 713.70s | Remaining: 1754.24s\n",
      "Processed 2780/9544 | Elapsed: 714.42s | Remaining: 1738.25s\n",
      "Processed 2800/9544 | Elapsed: 715.04s | Remaining: 1722.23s\n",
      "Processed 2820/9544 | Elapsed: 715.51s | Remaining: 1706.06s\n",
      "Processed 2840/9544 | Elapsed: 716.00s | Remaining: 1690.16s\n",
      "Processed 2860/9544 | Elapsed: 716.51s | Remaining: 1674.52s\n",
      "Processed 2880/9544 | Elapsed: 716.97s | Remaining: 1658.99s\n",
      "Processed 2900/9544 | Elapsed: 717.50s | Remaining: 1643.82s\n",
      "Processed 2920/9544 | Elapsed: 717.96s | Remaining: 1628.69s\n",
      "Processed 2940/9544 | Elapsed: 718.36s | Remaining: 1613.62s\n",
      "Processed 2960/9544 | Elapsed: 720.58s | Remaining: 1602.81s\n",
      "Processed 2980/9544 | Elapsed: 721.00s | Remaining: 1588.13s\n",
      "Processed 3000/9544 | Elapsed: 721.40s | Remaining: 1573.62s\n",
      "Processed 3020/9544 | Elapsed: 722.06s | Remaining: 1559.85s\n",
      "Processed 3040/9544 | Elapsed: 724.55s | Remaining: 1550.16s\n",
      "Processed 3060/9544 | Elapsed: 724.97s | Remaining: 1536.18s\n",
      "Processed 3080/9544 | Elapsed: 725.40s | Remaining: 1522.39s\n",
      "Processed 3100/9544 | Elapsed: 726.23s | Remaining: 1509.62s\n",
      "Processed 3120/9544 | Elapsed: 726.70s | Remaining: 1496.26s\n",
      "Processed 3140/9544 | Elapsed: 727.09s | Remaining: 1482.90s\n",
      "Processed 3160/9544 | Elapsed: 727.50s | Remaining: 1469.74s\n",
      "Processed 3180/9544 | Elapsed: 728.14s | Remaining: 1457.19s\n",
      "Processed 3200/9544 | Elapsed: 728.62s | Remaining: 1444.48s\n",
      "Processed 3220/9544 | Elapsed: 729.39s | Remaining: 1432.50s\n",
      "Processed 3240/9544 | Elapsed: 729.81s | Remaining: 1419.98s\n",
      "Processed 3260/9544 | Elapsed: 734.71s | Remaining: 1416.23s\n",
      "Processed 3280/9544 | Elapsed: 735.18s | Remaining: 1404.01s\n",
      "Processed 3300/9544 | Elapsed: 735.62s | Remaining: 1391.89s\n",
      "Processed 3320/9544 | Elapsed: 738.64s | Remaining: 1384.72s\n",
      "Processed 3340/9544 | Elapsed: 739.19s | Remaining: 1373.04s\n",
      "Processed 3360/9544 | Elapsed: 739.61s | Remaining: 1361.24s\n",
      "Processed 3380/9544 | Elapsed: 740.16s | Remaining: 1349.81s\n",
      "Processed 3400/9544 | Elapsed: 740.67s | Remaining: 1338.43s\n",
      "Processed 3420/9544 | Elapsed: 741.24s | Remaining: 1327.30s\n",
      "Processed 3440/9544 | Elapsed: 741.71s | Remaining: 1316.11s\n",
      "Processed 3460/9544 | Elapsed: 742.12s | Remaining: 1304.92s\n",
      "Processed 3480/9544 | Elapsed: 742.66s | Remaining: 1294.11s\n",
      "Processed 3500/9544 | Elapsed: 743.51s | Remaining: 1283.93s\n",
      "Processed 3520/9544 | Elapsed: 744.59s | Remaining: 1274.27s\n",
      "Processed 3540/9544 | Elapsed: 745.61s | Remaining: 1264.59s\n",
      "Processed 3560/9544 | Elapsed: 746.07s | Remaining: 1254.06s\n",
      "Processed 3580/9544 | Elapsed: 746.49s | Remaining: 1243.60s\n",
      "Processed 3600/9544 | Elapsed: 747.22s | Remaining: 1233.74s\n",
      "Processed 3620/9544 | Elapsed: 747.63s | Remaining: 1223.46s\n",
      "Processed 3640/9544 | Elapsed: 750.78s | Remaining: 1217.75s\n",
      "Processed 3660/9544 | Elapsed: 751.22s | Remaining: 1207.70s\n",
      "Processed 3680/9544 | Elapsed: 751.68s | Remaining: 1197.79s\n",
      "Processed 3700/9544 | Elapsed: 752.17s | Remaining: 1188.02s\n",
      "Processed 3720/9544 | Elapsed: 752.58s | Remaining: 1178.23s\n",
      "Processed 3740/9544 | Elapsed: 754.12s | Remaining: 1170.30s\n",
      "Processed 3760/9544 | Elapsed: 754.53s | Remaining: 1160.69s\n",
      "Processed 3780/9544 | Elapsed: 754.99s | Remaining: 1151.27s\n",
      "Processed 3800/9544 | Elapsed: 755.81s | Remaining: 1142.47s\n",
      "Processed 3820/9544 | Elapsed: 756.25s | Remaining: 1133.19s\n",
      "Processed 3840/9544 | Elapsed: 757.31s | Remaining: 1124.92s\n",
      "Processed 3860/9544 | Elapsed: 757.78s | Remaining: 1115.86s\n",
      "Processed 3880/9544 | Elapsed: 758.17s | Remaining: 1106.77s\n",
      "Processed 3900/9544 | Elapsed: 758.62s | Remaining: 1097.85s\n",
      "Error 504: <!DOCTYPE html>\n",
      "<!--[if lt IE 7]> <html class=\"no-js ie6 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if IE 7]>    <html class=\"no-js ie7 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if IE 8]>    <html class=\"no-js ie8 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if gt IE 8]><!--> <html class=\"no-js\" lang=\"en-US\"> <!--<![endif]-->\n",
      "<head>\n",
      "\n",
      "\n",
      "<title>api.openai.com | 504: Gateway time-out</title>\n",
      "<meta charset=\"UTF-8\" />\n",
      "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" />\n",
      "<meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\" />\n",
      "<meta name=\"robots\" content=\"noindex, nofollow\" />\n",
      "<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" />\n",
      "<link rel=\"stylesheet\" id=\"cf_styles-css\" href=\"/cdn-cgi/styles/main.css\" />\n",
      "\n",
      "\n",
      "</head>\n",
      "<body>\n",
      "<div id=\"cf-wrapper\">\n",
      "    <div id=\"cf-error-details\" class=\"p-0\">\n",
      "        <header class=\"mx-auto pt-10 lg:pt-6 lg:px-8 w-240 lg:w-full mb-8\">\n",
      "            <h1 class=\"inline-block sm:block sm:mb-2 font-light text-60 lg:text-4xl text-black-dark leading-tight mr-2\">\n",
      "              <span class=\"inline-block\">Gateway time-out</span>\n",
      "              <span class=\"code-label\">Error code 504</span>\n",
      "            </h1>\n",
      "            <div>\n",
      "               Visit <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_504&utm_campaign=api.openai.com\" target=\"_blank\" rel=\"noopener noreferrer\">cloudflare.com</a> for more information.\n",
      "            </div>\n",
      "            <div class=\"mt-3\">2025-05-14 05:46:57 UTC</div>\n",
      "        </header>\n",
      "        <div class=\"my-8 bg-gradient-gray\">\n",
      "            <div class=\"w-240 lg:w-full mx-auto\">\n",
      "                <div class=\"clearfix md:px-8\">\n",
      "                  \n",
      "<div id=\"cf-browser-status\" class=\" relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\n",
      "  <div class=\"relative mb-10 md:m-0\">\n",
      "    \n",
      "    <span class=\"cf-icon-browser block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
      "    <span class=\"cf-icon-ok w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
      "    \n",
      "  </div>\n",
      "  <span class=\"md:block w-full truncate\">You</span>\n",
      "  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
      "    \n",
      "    Browser\n",
      "    \n",
      "  </h3>\n",
      "  <span class=\"leading-1.3 text-2xl text-green-success\">Working</span>\n",
      "</div>\n",
      "\n",
      "<div id=\"cf-cloudflare-status\" class=\" relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\n",
      "  <div class=\"relative mb-10 md:m-0\">\n",
      "    <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_504&utm_campaign=api.openai.com\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
      "    <span class=\"cf-icon-cloud block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
      "    <span class=\"cf-icon-ok w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
      "    </a>\n",
      "  </div>\n",
      "  <span class=\"md:block w-full truncate\">Newark</span>\n",
      "  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
      "    <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_504&utm_campaign=api.openai.com\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
      "    Cloudflare\n",
      "    </a>\n",
      "  </h3>\n",
      "  <span class=\"leading-1.3 text-2xl text-green-success\">Working</span>\n",
      "</div>\n",
      "\n",
      "<div id=\"cf-host-status\" class=\"cf-error-source relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\n",
      "  <div class=\"relative mb-10 md:m-0\">\n",
      "    \n",
      "    <span class=\"cf-icon-server block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
      "    <span class=\"cf-icon-error w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
      "    \n",
      "  </div>\n",
      "  <span class=\"md:block w-full truncate\">api.openai.com</span>\n",
      "  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
      "    \n",
      "    Host\n",
      "    \n",
      "  </h3>\n",
      "  <span class=\"leading-1.3 text-2xl text-red-error\">Error</span>\n",
      "</div>\n",
      "\n",
      "                </div>\n",
      "            </div>\n",
      "        </div>\n",
      "\n",
      "        <div class=\"w-240 lg:w-full mx-auto mb-8 lg:px-8\">\n",
      "            <div class=\"clearfix\">\n",
      "                <div class=\"w-1/2 md:w-full float-left pr-6 md:pb-10 md:pr-0 leading-relaxed\">\n",
      "                    <h2 class=\"text-3xl font-normal leading-1.3 mb-4\">What happened?</h2>\n",
      "                    <p>The web server reported a gateway time-out error.</p>\n",
      "                </div>\n",
      "                <div class=\"w-1/2 md:w-full float-left leading-relaxed\">\n",
      "                    <h2 class=\"text-3xl font-normal leading-1.3 mb-4\">What can I do?</h2>\n",
      "                    <p class=\"mb-6\">Please try again in a few minutes.</p>\n",
      "                </div>\n",
      "            </div>\n",
      "        </div>\n",
      "\n",
      "        <div class=\"cf-error-footer cf-wrapper w-240 lg:w-full py-10 sm:py-4 sm:px-8 mx-auto text-center sm:text-left border-solid border-0 border-t border-gray-300\">\n",
      "  <p class=\"text-13\">\n",
      "    <span class=\"cf-footer-item sm:block sm:mb-1\">Cloudflare Ray ID: <strong class=\"font-semibold\">93f811c90da32223</strong></span>\n",
      "    <span class=\"cf-footer-separator sm:hidden\">&bull;</span>\n",
      "    <span id=\"cf-footer-item-ip\" class=\"cf-footer-item hidden sm:block sm:mb-1\">\n",
      "      Your IP:\n",
      "      <button type=\"button\" id=\"cf-footer-ip-reveal\" class=\"cf-footer-ip-reveal-btn\">Click to reveal</button>\n",
      "      <span class=\"hidden\" id=\"cf-footer-ip\">47.230.103.5</span>\n",
      "      <span class=\"cf-footer-separator sm:hidden\">&bull;</span>\n",
      "    </span>\n",
      "    <span class=\"cf-footer-item sm:block sm:mb-1\"><span>Performance &amp; security by</span> <a rel=\"noopener noreferrer\" href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_504&utm_campaign=api.openai.com\" id=\"brand_link\" target=\"_blank\">Cloudflare</a></span>\n",
      "    \n",
      "  </p>\n",
      "  <script>(function(){function d(){var b=a.getElementById(\"cf-footer-item-ip\"),c=a.getElementById(\"cf-footer-ip-reveal\");b&&\"classList\"in b&&(b.classList.remove(\"hidden\"),c.addEventListener(\"click\",function(){c.classList.add(\"hidden\");a.getElementById(\"cf-footer-ip\").classList.remove(\"hidden\")}))}var a=document;document.addEventListener&&a.addEventListener(\"DOMContentLoaded\",d)})();</script>\n",
      "</div><!-- /.error-footer -->\n",
      "\n",
      "\n",
      "    </div>\n",
      "</div>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "Processed 3920/9544 | Elapsed: 1058.74s | Remaining: 1518.97s\n",
      "Processed 3940/9544 | Elapsed: 1059.55s | Remaining: 1507.03s\n",
      "Processed 3960/9544 | Elapsed: 1060.10s | Remaining: 1494.85s\n",
      "Processed 3980/9544 | Elapsed: 1060.92s | Remaining: 1483.15s\n",
      "Processed 4000/9544 | Elapsed: 1061.56s | Remaining: 1471.32s\n",
      "Processed 4020/9544 | Elapsed: 1062.01s | Remaining: 1459.34s\n",
      "Processed 4040/9544 | Elapsed: 1062.47s | Remaining: 1447.49s\n",
      "Processed 4060/9544 | Elapsed: 1062.88s | Remaining: 1435.68s\n",
      "Processed 4080/9544 | Elapsed: 1063.31s | Remaining: 1424.00s\n",
      "Processed 4100/9544 | Elapsed: 1063.71s | Remaining: 1412.41s\n",
      "Processed 4120/9544 | Elapsed: 1064.14s | Remaining: 1400.95s\n",
      "Processed 4140/9544 | Elapsed: 1065.22s | Remaining: 1390.44s\n",
      "Processed 4160/9544 | Elapsed: 1065.78s | Remaining: 1379.37s\n",
      "Processed 4180/9544 | Elapsed: 1066.43s | Remaining: 1368.50s\n",
      "Processed 4200/9544 | Elapsed: 1067.58s | Remaining: 1358.37s\n",
      "Processed 4220/9544 | Elapsed: 1068.07s | Remaining: 1347.49s\n",
      "Processed 4240/9544 | Elapsed: 1068.62s | Remaining: 1336.79s\n",
      "Processed 4260/9544 | Elapsed: 1069.24s | Remaining: 1326.26s\n",
      "Processed 4280/9544 | Elapsed: 1069.69s | Remaining: 1315.62s\n",
      "Processed 4300/9544 | Elapsed: 1070.12s | Remaining: 1305.05s\n",
      "Processed 4320/9544 | Elapsed: 1070.91s | Remaining: 1295.01s\n",
      "Processed 4340/9544 | Elapsed: 1071.39s | Remaining: 1284.68s\n",
      "Processed 4360/9544 | Elapsed: 1071.78s | Remaining: 1274.34s\n",
      "Processed 4380/9544 | Elapsed: 1072.23s | Remaining: 1264.16s\n",
      "Processed 4400/9544 | Elapsed: 1072.77s | Remaining: 1254.16s\n",
      "Processed 4420/9544 | Elapsed: 1073.38s | Remaining: 1244.35s\n",
      "Processed 4440/9544 | Elapsed: 1073.91s | Remaining: 1234.51s\n",
      "Processed 4460/9544 | Elapsed: 1074.42s | Remaining: 1224.74s\n",
      "Processed 4480/9544 | Elapsed: 1075.10s | Remaining: 1215.25s\n",
      "Processed 4500/9544 | Elapsed: 1075.71s | Remaining: 1205.75s\n",
      "Processed 4520/9544 | Elapsed: 1076.21s | Remaining: 1196.21s\n",
      "Processed 4540/9544 | Elapsed: 1076.67s | Remaining: 1186.71s\n",
      "Processed 4560/9544 | Elapsed: 1077.22s | Remaining: 1177.39s\n",
      "Processed 4580/9544 | Elapsed: 1077.95s | Remaining: 1168.33s\n",
      "Processed 4600/9544 | Elapsed: 1078.43s | Remaining: 1159.08s\n",
      "Processed 4620/9544 | Elapsed: 1079.97s | Remaining: 1151.03s\n",
      "Processed 4640/9544 | Elapsed: 1080.58s | Remaining: 1142.06s\n",
      "Processed 4660/9544 | Elapsed: 1081.15s | Remaining: 1133.12s\n",
      "Processed 4680/9544 | Elapsed: 1081.55s | Remaining: 1124.07s\n",
      "Processed 4700/9544 | Elapsed: 1082.18s | Remaining: 1115.34s\n",
      "Processed 4720/9544 | Elapsed: 1082.59s | Remaining: 1106.44s\n",
      "Processed 4740/9544 | Elapsed: 1083.01s | Remaining: 1097.63s\n",
      "Processed 4760/9544 | Elapsed: 1083.53s | Remaining: 1088.99s\n",
      "Processed 4780/9544 | Elapsed: 1083.99s | Remaining: 1080.37s\n",
      "Processed 4800/9544 | Elapsed: 1084.43s | Remaining: 1071.78s\n",
      "Processed 4820/9544 | Elapsed: 1085.14s | Remaining: 1063.53s\n",
      "Processed 4840/9544 | Elapsed: 1085.68s | Remaining: 1055.18s\n",
      "Processed 4860/9544 | Elapsed: 1086.13s | Remaining: 1046.80s\n",
      "Processed 4880/9544 | Elapsed: 1086.67s | Remaining: 1038.58s\n",
      "Processed 4900/9544 | Elapsed: 1087.26s | Remaining: 1030.46s\n",
      "Processed 4920/9544 | Elapsed: 1087.66s | Remaining: 1022.23s\n",
      "Processed 4940/9544 | Elapsed: 1088.13s | Remaining: 1014.12s\n",
      "Processed 4960/9544 | Elapsed: 1088.62s | Remaining: 1006.09s\n",
      "Processed 4980/9544 | Elapsed: 1089.05s | Remaining: 998.08s\n",
      "Processed 5000/9544 | Elapsed: 1089.50s | Remaining: 990.14s\n",
      "Processed 5020/9544 | Elapsed: 1090.00s | Remaining: 982.30s\n",
      "Processed 5040/9544 | Elapsed: 1090.43s | Remaining: 974.47s\n",
      "Processed 5060/9544 | Elapsed: 1090.99s | Remaining: 966.80s\n",
      "Processed 5080/9544 | Elapsed: 1091.44s | Remaining: 959.09s\n",
      "Processed 5100/9544 | Elapsed: 1091.87s | Remaining: 951.42s\n",
      "Processed 5120/9544 | Elapsed: 1092.52s | Remaining: 944.00s\n",
      "Processed 5140/9544 | Elapsed: 1093.06s | Remaining: 936.55s\n",
      "Processed 5160/9544 | Elapsed: 1093.51s | Remaining: 929.06s\n",
      "Processed 5180/9544 | Elapsed: 1094.28s | Remaining: 921.90s\n",
      "Processed 5200/9544 | Elapsed: 1094.79s | Remaining: 914.57s\n",
      "Processed 5220/9544 | Elapsed: 1095.19s | Remaining: 907.20s\n",
      "Processed 5240/9544 | Elapsed: 1095.64s | Remaining: 899.93s\n",
      "Processed 5260/9544 | Elapsed: 1096.16s | Remaining: 892.77s\n",
      "Error 504: <!DOCTYPE html>\n",
      "<!--[if lt IE 7]> <html class=\"no-js ie6 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if IE 7]>    <html class=\"no-js ie7 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if IE 8]>    <html class=\"no-js ie8 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if gt IE 8]><!--> <html class=\"no-js\" lang=\"en-US\"> <!--<![endif]-->\n",
      "<head>\n",
      "\n",
      "\n",
      "<title>api.openai.com | 504: Gateway time-out</title>\n",
      "<meta charset=\"UTF-8\" />\n",
      "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" />\n",
      "<meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\" />\n",
      "<meta name=\"robots\" content=\"noindex, nofollow\" />\n",
      "<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" />\n",
      "<link rel=\"stylesheet\" id=\"cf_styles-css\" href=\"/cdn-cgi/styles/main.css\" />\n",
      "\n",
      "\n",
      "</head>\n",
      "<body>\n",
      "<div id=\"cf-wrapper\">\n",
      "    <div id=\"cf-error-details\" class=\"p-0\">\n",
      "        <header class=\"mx-auto pt-10 lg:pt-6 lg:px-8 w-240 lg:w-full mb-8\">\n",
      "            <h1 class=\"inline-block sm:block sm:mb-2 font-light text-60 lg:text-4xl text-black-dark leading-tight mr-2\">\n",
      "              <span class=\"inline-block\">Gateway time-out</span>\n",
      "              <span class=\"code-label\">Error code 504</span>\n",
      "            </h1>\n",
      "            <div>\n",
      "               Visit <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_504&utm_campaign=api.openai.com\" target=\"_blank\" rel=\"noopener noreferrer\">cloudflare.com</a> for more information.\n",
      "            </div>\n",
      "            <div class=\"mt-3\">2025-05-14 05:52:34 UTC</div>\n",
      "        </header>\n",
      "        <div class=\"my-8 bg-gradient-gray\">\n",
      "            <div class=\"w-240 lg:w-full mx-auto\">\n",
      "                <div class=\"clearfix md:px-8\">\n",
      "                  \n",
      "<div id=\"cf-browser-status\" class=\" relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\n",
      "  <div class=\"relative mb-10 md:m-0\">\n",
      "    \n",
      "    <span class=\"cf-icon-browser block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
      "    <span class=\"cf-icon-ok w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
      "    \n",
      "  </div>\n",
      "  <span class=\"md:block w-full truncate\">You</span>\n",
      "  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
      "    \n",
      "    Browser\n",
      "    \n",
      "  </h3>\n",
      "  <span class=\"leading-1.3 text-2xl text-green-success\">Working</span>\n",
      "</div>\n",
      "\n",
      "<div id=\"cf-cloudflare-status\" class=\" relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\n",
      "  <div class=\"relative mb-10 md:m-0\">\n",
      "    <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_504&utm_campaign=api.openai.com\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
      "    <span class=\"cf-icon-cloud block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
      "    <span class=\"cf-icon-ok w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
      "    </a>\n",
      "  </div>\n",
      "  <span class=\"md:block w-full truncate\">Newark</span>\n",
      "  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
      "    <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_504&utm_campaign=api.openai.com\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
      "    Cloudflare\n",
      "    </a>\n",
      "  </h3>\n",
      "  <span class=\"leading-1.3 text-2xl text-green-success\">Working</span>\n",
      "</div>\n",
      "\n",
      "<div id=\"cf-host-status\" class=\"cf-error-source relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\n",
      "  <div class=\"relative mb-10 md:m-0\">\n",
      "    \n",
      "    <span class=\"cf-icon-server block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
      "    <span class=\"cf-icon-error w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
      "    \n",
      "  </div>\n",
      "  <span class=\"md:block w-full truncate\">api.openai.com</span>\n",
      "  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
      "    \n",
      "    Host\n",
      "    \n",
      "  </h3>\n",
      "  <span class=\"leading-1.3 text-2xl text-red-error\">Error</span>\n",
      "</div>\n",
      "\n",
      "                </div>\n",
      "            </div>\n",
      "        </div>\n",
      "\n",
      "        <div class=\"w-240 lg:w-full mx-auto mb-8 lg:px-8\">\n",
      "            <div class=\"clearfix\">\n",
      "                <div class=\"w-1/2 md:w-full float-left pr-6 md:pb-10 md:pr-0 leading-relaxed\">\n",
      "                    <h2 class=\"text-3xl font-normal leading-1.3 mb-4\">What happened?</h2>\n",
      "                    <p>The web server reported a gateway time-out error.</p>\n",
      "                </div>\n",
      "                <div class=\"w-1/2 md:w-full float-left leading-relaxed\">\n",
      "                    <h2 class=\"text-3xl font-normal leading-1.3 mb-4\">What can I do?</h2>\n",
      "                    <p class=\"mb-6\">Please try again in a few minutes.</p>\n",
      "                </div>\n",
      "            </div>\n",
      "        </div>\n",
      "\n",
      "        <div class=\"cf-error-footer cf-wrapper w-240 lg:w-full py-10 sm:py-4 sm:px-8 mx-auto text-center sm:text-left border-solid border-0 border-t border-gray-300\">\n",
      "  <p class=\"text-13\">\n",
      "    <span class=\"cf-footer-item sm:block sm:mb-1\">Cloudflare Ray ID: <strong class=\"font-semibold\">93f81a06980c3902</strong></span>\n",
      "    <span class=\"cf-footer-separator sm:hidden\">&bull;</span>\n",
      "    <span id=\"cf-footer-item-ip\" class=\"cf-footer-item hidden sm:block sm:mb-1\">\n",
      "      Your IP:\n",
      "      <button type=\"button\" id=\"cf-footer-ip-reveal\" class=\"cf-footer-ip-reveal-btn\">Click to reveal</button>\n",
      "      <span class=\"hidden\" id=\"cf-footer-ip\">47.230.103.5</span>\n",
      "      <span class=\"cf-footer-separator sm:hidden\">&bull;</span>\n",
      "    </span>\n",
      "    <span class=\"cf-footer-item sm:block sm:mb-1\"><span>Performance &amp; security by</span> <a rel=\"noopener noreferrer\" href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_504&utm_campaign=api.openai.com\" id=\"brand_link\" target=\"_blank\">Cloudflare</a></span>\n",
      "    \n",
      "  </p>\n",
      "  <script>(function(){function d(){var b=a.getElementById(\"cf-footer-item-ip\"),c=a.getElementById(\"cf-footer-ip-reveal\");b&&\"classList\"in b&&(b.classList.remove(\"hidden\"),c.addEventListener(\"click\",function(){c.classList.add(\"hidden\");a.getElementById(\"cf-footer-ip\").classList.remove(\"hidden\")}))}var a=document;document.addEventListener&&a.addEventListener(\"DOMContentLoaded\",d)})();</script>\n",
      "</div><!-- /.error-footer -->\n",
      "\n",
      "\n",
      "    </div>\n",
      "</div>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "Processed 5280/9544 | Elapsed: 1396.35s | Remaining: 1127.66s\n",
      "Processed 5300/9544 | Elapsed: 1396.96s | Remaining: 1118.62s\n",
      "Processed 5320/9544 | Elapsed: 1397.44s | Remaining: 1109.54s\n",
      "Processed 5340/9544 | Elapsed: 1398.23s | Remaining: 1100.78s\n",
      "Processed 5360/9544 | Elapsed: 1399.02s | Remaining: 1092.07s\n",
      "Processed 5380/9544 | Elapsed: 1399.60s | Remaining: 1083.26s\n",
      "Processed 5400/9544 | Elapsed: 1400.13s | Remaining: 1074.47s\n",
      "Processed 5420/9544 | Elapsed: 1400.73s | Remaining: 1065.79s\n",
      "Processed 5440/9544 | Elapsed: 1401.42s | Remaining: 1057.25s\n",
      "Processed 5460/9544 | Elapsed: 1402.46s | Remaining: 1049.02s\n",
      "Processed 5480/9544 | Elapsed: 1403.21s | Remaining: 1040.63s\n",
      "Processed 5500/9544 | Elapsed: 1403.89s | Remaining: 1032.24s\n",
      "Processed 5520/9544 | Elapsed: 1404.43s | Remaining: 1023.81s\n",
      "Processed 5540/9544 | Elapsed: 1405.30s | Remaining: 1015.67s\n",
      "Processed 5560/9544 | Elapsed: 1405.76s | Remaining: 1007.29s\n",
      "Processed 5580/9544 | Elapsed: 1406.45s | Remaining: 999.13s\n",
      "Processed 5600/9544 | Elapsed: 1407.28s | Remaining: 991.13s\n",
      "Processed 5620/9544 | Elapsed: 1407.86s | Remaining: 983.00s\n",
      "Processed 5640/9544 | Elapsed: 1408.35s | Remaining: 974.86s\n",
      "Processed 5660/9544 | Elapsed: 1408.91s | Remaining: 966.82s\n",
      "Processed 5680/9544 | Elapsed: 1409.40s | Remaining: 958.79s\n",
      "Processed 5700/9544 | Elapsed: 1410.33s | Remaining: 951.11s\n",
      "Processed 5720/9544 | Elapsed: 1410.91s | Remaining: 943.23s\n",
      "Processed 5740/9544 | Elapsed: 1411.39s | Remaining: 935.35s\n",
      "Processed 5760/9544 | Elapsed: 1411.85s | Remaining: 927.51s\n",
      "Processed 5780/9544 | Elapsed: 1412.27s | Remaining: 919.69s\n",
      "Processed 5800/9544 | Elapsed: 1412.78s | Remaining: 911.97s\n",
      "Processed 5820/9544 | Elapsed: 1413.37s | Remaining: 904.36s\n",
      "Processed 5840/9544 | Elapsed: 1416.22s | Remaining: 898.23s\n",
      "Processed 5860/9544 | Elapsed: 1416.69s | Remaining: 890.63s\n",
      "Processed 5880/9544 | Elapsed: 1597.67s | Remaining: 995.56s\n",
      "Processed 5900/9544 | Elapsed: 1598.31s | Remaining: 987.16s\n",
      "Processed 5920/9544 | Elapsed: 1598.89s | Remaining: 978.78s\n",
      "Processed 5940/9544 | Elapsed: 1599.55s | Remaining: 970.50s\n",
      "Processed 5960/9544 | Elapsed: 1600.02s | Remaining: 962.16s\n",
      "Processed 5980/9544 | Elapsed: 1600.43s | Remaining: 953.83s\n",
      "Processed 6000/9544 | Elapsed: 1600.91s | Remaining: 945.61s\n",
      "Processed 6020/9544 | Elapsed: 1602.14s | Remaining: 937.86s\n",
      "Processed 6040/9544 | Elapsed: 1602.94s | Remaining: 929.92s\n",
      "Processed 6060/9544 | Elapsed: 1603.39s | Remaining: 921.82s\n",
      "Processed 6080/9544 | Elapsed: 1603.86s | Remaining: 913.78s\n",
      "Processed 6100/9544 | Elapsed: 1604.47s | Remaining: 905.87s\n",
      "Processed 6120/9544 | Elapsed: 1605.15s | Remaining: 898.04s\n",
      "Processed 6140/9544 | Elapsed: 1605.58s | Remaining: 890.13s\n",
      "Processed 6160/9544 | Elapsed: 1606.23s | Remaining: 882.39s\n",
      "Processed 6180/9544 | Elapsed: 1610.06s | Remaining: 876.42s\n",
      "Processed 6200/9544 | Elapsed: 1610.48s | Remaining: 868.62s\n",
      "Processed 6220/9544 | Elapsed: 1610.88s | Remaining: 860.86s\n",
      "Processed 6240/9544 | Elapsed: 1611.27s | Remaining: 853.15s\n",
      "Processed 6260/9544 | Elapsed: 1611.74s | Remaining: 845.52s\n",
      "Processed 6280/9544 | Elapsed: 1612.33s | Remaining: 838.00s\n",
      "Processed 6300/9544 | Elapsed: 1613.06s | Remaining: 830.60s\n",
      "Processed 6320/9544 | Elapsed: 1613.66s | Remaining: 823.17s\n",
      "Processed 6340/9544 | Elapsed: 1614.05s | Remaining: 815.68s\n",
      "Processed 6360/9544 | Elapsed: 1614.45s | Remaining: 808.24s\n",
      "Processed 6380/9544 | Elapsed: 1615.00s | Remaining: 800.92s\n",
      "Processed 6400/9544 | Elapsed: 1615.45s | Remaining: 793.59s\n",
      "Processed 6420/9544 | Elapsed: 1615.89s | Remaining: 786.30s\n",
      "Processed 6440/9544 | Elapsed: 1616.55s | Remaining: 779.16s\n",
      "Processed 6460/9544 | Elapsed: 1617.09s | Remaining: 772.00s\n",
      "Processed 6480/9544 | Elapsed: 1617.75s | Remaining: 764.93s\n",
      "Processed 6500/9544 | Elapsed: 1618.22s | Remaining: 757.82s\n",
      "Processed 6520/9544 | Elapsed: 1618.92s | Remaining: 750.86s\n",
      "Processed 6540/9544 | Elapsed: 1619.62s | Remaining: 743.94s\n",
      "Processed 6560/9544 | Elapsed: 1620.12s | Remaining: 736.96s\n",
      "Processed 6580/9544 | Elapsed: 1620.59s | Remaining: 730.00s\n",
      "Processed 6600/9544 | Elapsed: 1621.00s | Remaining: 723.07s\n",
      "Processed 6620/9544 | Elapsed: 1621.41s | Remaining: 716.16s\n",
      "Processed 6640/9544 | Elapsed: 1621.92s | Remaining: 709.35s\n",
      "Processed 6660/9544 | Elapsed: 1622.32s | Remaining: 702.52s\n",
      "Processed 6680/9544 | Elapsed: 1622.91s | Remaining: 695.81s\n",
      "Processed 6700/9544 | Elapsed: 1623.36s | Remaining: 689.08s\n",
      "Processed 6720/9544 | Elapsed: 1624.09s | Remaining: 682.50s\n",
      "Processed 6740/9544 | Elapsed: 1624.51s | Remaining: 675.83s\n",
      "Processed 6760/9544 | Elapsed: 1625.04s | Remaining: 669.25s\n",
      "Processed 6780/9544 | Elapsed: 1625.47s | Remaining: 662.65s\n",
      "Processed 6800/9544 | Elapsed: 1625.84s | Remaining: 656.08s\n",
      "Processed 6820/9544 | Elapsed: 1626.27s | Remaining: 649.55s\n",
      "Processed 6840/9544 | Elapsed: 1626.74s | Remaining: 643.09s\n",
      "Processed 6860/9544 | Elapsed: 1627.39s | Remaining: 636.72s\n",
      "Processed 6880/9544 | Elapsed: 1627.83s | Remaining: 630.31s\n",
      "Processed 6900/9544 | Elapsed: 1630.00s | Remaining: 624.60s\n",
      "Processed 6920/9544 | Elapsed: 1630.43s | Remaining: 618.24s\n",
      "Processed 6940/9544 | Elapsed: 1631.67s | Remaining: 612.23s\n",
      "Processed 6960/9544 | Elapsed: 1632.10s | Remaining: 605.94s\n",
      "Processed 6980/9544 | Elapsed: 1632.51s | Remaining: 599.68s\n",
      "Processed 7000/9544 | Elapsed: 1633.22s | Remaining: 593.56s\n",
      "Processed 7020/9544 | Elapsed: 1634.00s | Remaining: 587.50s\n",
      "Processed 7040/9544 | Elapsed: 1634.41s | Remaining: 581.33s\n",
      "Processed 7060/9544 | Elapsed: 1634.87s | Remaining: 575.22s\n",
      "Processed 7080/9544 | Elapsed: 1635.48s | Remaining: 569.18s\n",
      "Processed 7100/9544 | Elapsed: 1635.89s | Remaining: 563.12s\n",
      "Processed 7120/9544 | Elapsed: 1636.31s | Remaining: 557.08s\n",
      "Processed 7140/9544 | Elapsed: 1637.19s | Remaining: 551.23s\n",
      "Processed 7160/9544 | Elapsed: 1637.88s | Remaining: 545.35s\n",
      "Processed 7180/9544 | Elapsed: 1638.31s | Remaining: 539.41s\n",
      "Processed 7200/9544 | Elapsed: 1638.76s | Remaining: 533.51s\n",
      "Processed 7220/9544 | Elapsed: 1639.23s | Remaining: 527.64s\n",
      "Processed 7240/9544 | Elapsed: 1639.87s | Remaining: 521.86s\n",
      "Processed 7260/9544 | Elapsed: 1640.29s | Remaining: 516.03s\n",
      "Processed 7280/9544 | Elapsed: 1640.74s | Remaining: 510.25s\n",
      "Processed 7300/9544 | Elapsed: 1641.15s | Remaining: 504.49s\n",
      "Processed 7320/9544 | Elapsed: 1641.61s | Remaining: 498.76s\n",
      "Processed 7340/9544 | Elapsed: 1642.00s | Remaining: 493.05s\n",
      "Processed 7360/9544 | Elapsed: 1642.76s | Remaining: 487.47s\n",
      "Processed 7380/9544 | Elapsed: 1643.48s | Remaining: 481.91s\n",
      "Processed 7400/9544 | Elapsed: 1643.92s | Remaining: 476.29s\n",
      "Processed 7420/9544 | Elapsed: 1644.34s | Remaining: 470.70s\n",
      "Processed 7440/9544 | Elapsed: 1644.78s | Remaining: 465.14s\n",
      "Processed 7460/9544 | Elapsed: 1645.19s | Remaining: 459.59s\n",
      "Processed 7480/9544 | Elapsed: 1645.61s | Remaining: 454.08s\n",
      "Processed 7500/9544 | Elapsed: 1646.35s | Remaining: 448.68s\n",
      "Processed 7520/9544 | Elapsed: 1646.75s | Remaining: 443.22s\n",
      "Processed 7540/9544 | Elapsed: 1647.17s | Remaining: 437.79s\n",
      "Processed 7560/9544 | Elapsed: 1647.72s | Remaining: 432.42s\n",
      "Processed 7580/9544 | Elapsed: 1648.36s | Remaining: 427.09s\n",
      "Processed 7600/9544 | Elapsed: 1648.97s | Remaining: 421.79s\n",
      "Processed 7620/9544 | Elapsed: 1650.13s | Remaining: 416.65s\n",
      "Processed 7640/9544 | Elapsed: 1650.55s | Remaining: 411.34s\n",
      "Processed 7660/9544 | Elapsed: 1651.04s | Remaining: 406.08s\n",
      "Processed 7680/9544 | Elapsed: 1651.47s | Remaining: 400.83s\n",
      "Processed 7700/9544 | Elapsed: 1651.94s | Remaining: 395.61s\n",
      "Processed 7720/9544 | Elapsed: 1652.37s | Remaining: 390.41s\n",
      "Processed 7740/9544 | Elapsed: 1652.93s | Remaining: 385.26s\n",
      "Processed 7760/9544 | Elapsed: 1653.36s | Remaining: 380.10s\n",
      "Processed 7780/9544 | Elapsed: 1653.76s | Remaining: 374.97s\n",
      "Processed 7800/9544 | Elapsed: 1654.21s | Remaining: 369.87s\n",
      "Processed 7820/9544 | Elapsed: 1654.65s | Remaining: 364.78s\n",
      "Processed 7840/9544 | Elapsed: 1655.16s | Remaining: 359.74s\n",
      "Processed 7860/9544 | Elapsed: 1655.81s | Remaining: 354.76s\n",
      "Processed 7880/9544 | Elapsed: 1656.38s | Remaining: 349.77s\n",
      "Processed 7900/9544 | Elapsed: 1656.91s | Remaining: 344.80s\n",
      "Processed 7920/9544 | Elapsed: 1657.36s | Remaining: 339.84s\n",
      "Processed 7940/9544 | Elapsed: 1658.18s | Remaining: 334.98s\n",
      "Processed 7960/9544 | Elapsed: 1658.95s | Remaining: 330.12s\n",
      "Processed 7980/9544 | Elapsed: 1659.36s | Remaining: 325.22s\n",
      "Processed 8000/9544 | Elapsed: 1660.13s | Remaining: 320.41s\n",
      "Processed 8020/9544 | Elapsed: 1661.44s | Remaining: 315.71s\n",
      "Processed 8040/9544 | Elapsed: 1661.94s | Remaining: 310.89s\n",
      "Processed 8060/9544 | Elapsed: 1662.45s | Remaining: 306.09s\n",
      "Processed 8080/9544 | Elapsed: 1663.05s | Remaining: 301.32s\n",
      "Processed 8100/9544 | Elapsed: 1663.62s | Remaining: 296.58s\n",
      "Processed 8120/9544 | Elapsed: 1664.03s | Remaining: 291.82s\n",
      "Processed 8140/9544 | Elapsed: 1664.54s | Remaining: 287.10s\n",
      "Processed 8160/9544 | Elapsed: 1665.04s | Remaining: 282.40s\n",
      "Processed 8180/9544 | Elapsed: 1665.47s | Remaining: 277.71s\n",
      "Processed 8200/9544 | Elapsed: 1667.78s | Remaining: 273.35s\n",
      "Processed 8220/9544 | Elapsed: 1668.33s | Remaining: 268.72s\n",
      "Processed 8240/9544 | Elapsed: 1668.93s | Remaining: 264.11s\n",
      "Processed 8260/9544 | Elapsed: 1669.33s | Remaining: 259.49s\n",
      "Processed 8280/9544 | Elapsed: 1669.75s | Remaining: 254.90s\n",
      "Processed 8300/9544 | Elapsed: 1670.30s | Remaining: 250.34s\n",
      "Processed 8320/9544 | Elapsed: 1670.77s | Remaining: 245.80s\n",
      "Processed 8340/9544 | Elapsed: 1671.19s | Remaining: 241.26s\n",
      "Processed 8360/9544 | Elapsed: 1671.60s | Remaining: 236.74s\n",
      "Processed 8380/9544 | Elapsed: 1672.14s | Remaining: 232.26s\n",
      "Processed 8400/9544 | Elapsed: 1672.57s | Remaining: 227.79s\n",
      "Processed 8420/9544 | Elapsed: 1673.13s | Remaining: 223.35s\n",
      "Processed 8440/9544 | Elapsed: 1673.54s | Remaining: 218.91s\n",
      "Processed 8460/9544 | Elapsed: 1673.99s | Remaining: 214.49s\n",
      "Processed 8480/9544 | Elapsed: 1674.60s | Remaining: 210.11s\n",
      "Processed 8500/9544 | Elapsed: 1675.10s | Remaining: 205.74s\n",
      "Processed 8520/9544 | Elapsed: 1675.53s | Remaining: 201.38s\n",
      "Processed 8540/9544 | Elapsed: 1676.00s | Remaining: 197.04s\n",
      "Processed 8560/9544 | Elapsed: 1676.43s | Remaining: 192.71s\n",
      "Processed 8580/9544 | Elapsed: 1676.82s | Remaining: 188.40s\n",
      "Processed 8600/9544 | Elapsed: 1677.49s | Remaining: 184.13s\n",
      "Processed 8620/9544 | Elapsed: 1677.90s | Remaining: 179.86s\n",
      "Processed 8640/9544 | Elapsed: 1678.38s | Remaining: 175.61s\n",
      "Processed 8660/9544 | Elapsed: 1678.97s | Remaining: 171.39s\n",
      "Processed 8680/9544 | Elapsed: 1679.43s | Remaining: 167.17s\n",
      "Processed 8700/9544 | Elapsed: 1679.84s | Remaining: 162.96s\n",
      "Processed 8720/9544 | Elapsed: 1680.36s | Remaining: 158.79s\n",
      "Processed 8740/9544 | Elapsed: 1680.80s | Remaining: 154.62s\n",
      "Processed 8760/9544 | Elapsed: 1681.24s | Remaining: 150.47s\n",
      "Processed 8780/9544 | Elapsed: 1681.86s | Remaining: 146.35s\n",
      "Processed 8800/9544 | Elapsed: 1682.39s | Remaining: 142.24s\n",
      "Processed 8820/9544 | Elapsed: 1683.17s | Remaining: 138.17s\n",
      "Processed 8840/9544 | Elapsed: 1683.61s | Remaining: 134.08s\n",
      "Processed 8860/9544 | Elapsed: 1684.36s | Remaining: 130.03s\n",
      "Processed 8880/9544 | Elapsed: 1685.32s | Remaining: 126.02s\n",
      "Processed 8900/9544 | Elapsed: 1685.74s | Remaining: 121.98s\n",
      "Processed 8920/9544 | Elapsed: 1686.14s | Remaining: 117.95s\n",
      "Processed 8940/9544 | Elapsed: 1686.58s | Remaining: 113.95s\n",
      "Processed 8960/9544 | Elapsed: 1687.31s | Remaining: 109.98s\n",
      "Processed 8980/9544 | Elapsed: 1687.79s | Remaining: 106.00s\n",
      "Processed 9000/9544 | Elapsed: 1688.23s | Remaining: 102.04s\n",
      "Embedding Error: \n",
      "Processed 9020/9544 | Elapsed: 1987.70s | Remaining: 115.47s\n",
      "Processed 9040/9544 | Elapsed: 1988.48s | Remaining: 110.86s\n",
      "Processed 9060/9544 | Elapsed: 1989.05s | Remaining: 106.26s\n",
      "Processed 9080/9544 | Elapsed: 1989.53s | Remaining: 101.67s\n",
      "Processed 9100/9544 | Elapsed: 1990.14s | Remaining: 97.10s\n",
      "Processed 9120/9544 | Elapsed: 1990.68s | Remaining: 92.55s\n",
      "Processed 9140/9544 | Elapsed: 1991.42s | Remaining: 88.02s\n",
      "Processed 9160/9544 | Elapsed: 1992.05s | Remaining: 83.51s\n",
      "Processed 9180/9544 | Elapsed: 1992.50s | Remaining: 79.01s\n",
      "Processed 9200/9544 | Elapsed: 1992.94s | Remaining: 74.52s\n",
      "Processed 9220/9544 | Elapsed: 1993.52s | Remaining: 70.05s\n",
      "Processed 9240/9544 | Elapsed: 1994.18s | Remaining: 65.61s\n",
      "Processed 9260/9544 | Elapsed: 1997.37s | Remaining: 61.26s\n",
      "Processed 9280/9544 | Elapsed: 1997.90s | Remaining: 56.84s\n",
      "Processed 9300/9544 | Elapsed: 1998.36s | Remaining: 52.43s\n",
      "Processed 9320/9544 | Elapsed: 1998.78s | Remaining: 48.04s\n",
      "Processed 9340/9544 | Elapsed: 1999.30s | Remaining: 43.67s\n",
      "Processed 9360/9544 | Elapsed: 2000.00s | Remaining: 39.32s\n",
      "Processed 9380/9544 | Elapsed: 2000.41s | Remaining: 34.98s\n",
      "Processed 9400/9544 | Elapsed: 2001.07s | Remaining: 30.65s\n",
      "Processed 9420/9544 | Elapsed: 2001.46s | Remaining: 26.35s\n",
      "Processed 9440/9544 | Elapsed: 2002.22s | Remaining: 22.06s\n",
      "Processed 9460/9544 | Elapsed: 2003.52s | Remaining: 17.79s\n",
      "Processed 9480/9544 | Elapsed: 2004.19s | Remaining: 13.53s\n",
      "Processed 9500/9544 | Elapsed: 2004.73s | Remaining: 9.29s\n",
      "Processed 9520/9544 | Elapsed: 2005.27s | Remaining: 5.06s\n",
      "Processed 9540/9544 | Elapsed: 2005.69s | Remaining: 0.84s\n",
      "Processed 9544/9544 | Elapsed: 2006.23s | Remaining: 0.00s\n",
      "Embedding generation completed in 2006.62 seconds.\n",
      "Number of zero vectors: 5\n",
      " FAISS index saved as: resume_index.faiss\n",
      " Metadata saved as: resume_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import openai\n",
    "import faiss\n",
    "import numpy as np\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "\n",
    "openai.api_key = api_key\n",
    "\n",
    "# Apply nest_asyncio to prevent RuntimeError in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Define Data Paths\n",
    "data_path = 'resume_data.csv'\n",
    "faiss_path = 'resume_index.faiss'\n",
    "metadata_path = 'resume_metadata.csv'\n",
    "\n",
    "# Data Preprocessing\n",
    "df = pd.read_csv(data_path, encoding='utf-8')\n",
    "df.rename(columns=lambda x: x.lstrip(\"\\ufeff\"), inplace=True)\n",
    "\n",
    "def assemble_resume(row):\n",
    "    parts = []\n",
    "    if pd.notna(row.get(\"career_objective\")):\n",
    "        parts.append(row[\"career_objective\"])\n",
    "    if pd.notna(row.get(\"skills\")):\n",
    "        parts.append(\"Skills: \" + row[\"skills\"])\n",
    "    if pd.notna(row.get(\"responsibilities\")):\n",
    "        parts.append(\"Responsibilities: \" + row[\"responsibilities\"])\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "def assemble_jd(row):\n",
    "    parts = []\n",
    "    if pd.notna(row.get(\"job_position_name\")):\n",
    "        parts.append(\"Position: \" + row[\"job_position_name\"])\n",
    "    if pd.notna(row.get(\"skills_required\")):\n",
    "        parts.append(\"Required Skills: \" + row[\"skills_required\"])\n",
    "    if pd.notna(row.get(\"responsibilities.1\")):\n",
    "        parts.append(\"Responsibilities: \" + row[\"responsibilities.1\"])\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "df['resume_text'] = df.apply(assemble_resume, axis=1)\n",
    "df['job_description'] = df.apply(assemble_jd, axis=1)\n",
    "df['resume_id'] = range(len(df))\n",
    "\n",
    "# Async Embedding Generation\n",
    "async def async_get_embedding(session, text):\n",
    "    \"\"\" Asynchronous embedding generation using OpenAI API. \"\"\"\n",
    "    try:\n",
    "        async with session.post(\n",
    "            \"https://api.openai.com/v1/embeddings\",\n",
    "            headers={\"Authorization\": f\"Bearer {api_key}\"},\n",
    "            json={\"input\": text, \"model\": \"text-embedding-ada-002\"}\n",
    "        ) as response:\n",
    "            if response.status != 200:\n",
    "                print(f\"Error {response.status}: {await response.text()}\")\n",
    "                return np.zeros(1536)\n",
    "            data = await response.json()\n",
    "            return data['data'][0]['embedding']\n",
    "    except Exception as e:\n",
    "        print(f\"Embedding Error: {e}\")\n",
    "        return np.zeros(1536)\n",
    "\n",
    "async def process_embeddings(data, batch_size=20):\n",
    "    embeddings = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Async HTTP session\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        for start in range(0, len(data), batch_size):\n",
    "            batch = data[start:start + batch_size]\n",
    "            tasks = [async_get_embedding(session, text) for text in batch]\n",
    "            batch_embeddings = await asyncio.gather(*tasks)\n",
    "            embeddings.extend(batch_embeddings)\n",
    "\n",
    "            # Progress logging\n",
    "            elapsed = time.time() - start_time\n",
    "            processed = start + len(batch)\n",
    "            remaining = len(data) - processed\n",
    "            est_remaining_time = (elapsed / processed) * remaining if processed else 0\n",
    "            print(f\"Processed {processed}/{len(data)} | Elapsed: {elapsed:.2f}s | Remaining: {est_remaining_time:.2f}s\")\n",
    "    \n",
    "    return np.array(embeddings)\n",
    "\n",
    "# Execute Async Embedding Generation\n",
    "print(\"Starting async embedding generation...\")\n",
    "start_time = time.time()\n",
    "embeddings = asyncio.run(process_embeddings(df['resume_text'].tolist(), batch_size=20))\n",
    "print(f\"Embedding generation completed in {time.time() - start_time:.2f} seconds.\")\n",
    "\n",
    "# Check for Zero Vectors\n",
    "num_zero_vectors = np.sum(np.all(embeddings == 0, axis=1))\n",
    "print(f\"Number of zero vectors: {num_zero_vectors}\")\n",
    "\n",
    "# Build and Save FAISS Index\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings)\n",
    "faiss.write_index(index, faiss_path)\n",
    "df.to_csv(metadata_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\" FAISS index saved as: {faiss_path}\")\n",
    "print(f\" Metadata saved as: {metadata_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49ca3e06-b569-48f1-98b9-fe154ff08cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to fine_tune_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Define paths\n",
    "data_path = 'resume_data.csv'\n",
    "output_path = 'fine_tune_data.jsonl'\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(data_path, encoding='utf-8')\n",
    "df.rename(columns=lambda x: x.lstrip(\"\\ufeff\"), inplace=True)\n",
    "\n",
    "# Function to assemble resume text\n",
    "def assemble_resume(row):\n",
    "    parts = []\n",
    "    if pd.notna(row.get(\"career_objective\")):\n",
    "        parts.append(row[\"career_objective\"])\n",
    "    if pd.notna(row.get(\"skills\")):\n",
    "        parts.append(\"Skills: \" + row[\"skills\"])\n",
    "    if pd.notna(row.get(\"responsibilities\")):\n",
    "        parts.append(\"Responsibilities: \" + row[\"responsibilities\"])\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "# Function to assemble job description text\n",
    "def assemble_jd(row):\n",
    "    parts = []\n",
    "    if pd.notna(row.get(\"job_position_name\")):\n",
    "        parts.append(\"Position: \" + row[\"job_position_name\"])\n",
    "    if pd.notna(row.get(\"skills_required\")):\n",
    "        parts.append(\"Required Skills: \" + row[\"skills_required\"])\n",
    "    if pd.notna(row.get(\"responsibilities.1\")):\n",
    "        parts.append(\"Responsibilities: \" + row[\"responsibilities.1\"])\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "# Convert to JSONL format\n",
    "with open(output_path, 'w', encoding='utf-8') as outfile:\n",
    "    for _, row in df.iterrows():\n",
    "        resume_text = assemble_resume(row)\n",
    "        jd_text = assemble_jd(row)\n",
    "        if resume_text.strip() and jd_text.strip():\n",
    "            data = {\n",
    "                \"prompt\": jd_text.strip() + \"\\n\\nGenerate Resume：\",\n",
    "                \"completion\": \" \" + resume_text.strip()\n",
    "            }\n",
    "            json.dump(data, outfile, ensure_ascii=False)\n",
    "            outfile.write(\"\\n\")\n",
    "\n",
    "print(f\"Data successfully saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "195c567d-f683-4115-b0d2-07957ee8528d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to fine_tune_data.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "465677bcd0ef4b98ab9905b1b78c6d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "699654c78c454623a2d8f82a3882f50d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9544 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rick\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: zz3237 (zz3237-columbia-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Rick\\Desktop\\5293\\final project notebook running check\\wandb\\run-20250514_021507-72aotqmh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/zz3237-columbia-university/huggingface/runs/72aotqmh' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/zz3237-columbia-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/zz3237-columbia-university/huggingface' target=\"_blank\">https://wandb.ai/zz3237-columbia-university/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/zz3237-columbia-university/huggingface/runs/72aotqmh' target=\"_blank\">https://wandb.ai/zz3237-columbia-university/huggingface/runs/72aotqmh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rick\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1193' max='1193' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1193/1193 1:27:26, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.821800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.096200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.832800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.745700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.679800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.652400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.621700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.557600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.533500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.511200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.486500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning completed!\n",
      "Model and tokenizer saved to ./fine_tuned_model\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from transformers import Trainer, TrainingArguments, GPT2Tokenizer, GPT2LMHeadModel\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "# Define paths\n",
    "data_path = 'resume_data.csv'\n",
    "output_path = 'fine_tune_data.jsonl'\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(data_path, encoding='utf-8')\n",
    "df.rename(columns=lambda x: x.lstrip(\"\\ufeff\"), inplace=True)\n",
    "\n",
    "# Function to assemble resume text\n",
    "def assemble_resume(row):\n",
    "    parts = []\n",
    "    if pd.notna(row.get(\"career_objective\")):\n",
    "        parts.append(row[\"career_objective\"])\n",
    "    if pd.notna(row.get(\"skills\")):\n",
    "        parts.append(\"Skills: \" + row[\"skills\"])\n",
    "    if pd.notna(row.get(\"responsibilities\")):\n",
    "        parts.append(\"Responsibilities: \" + row[\"responsibilities\"])\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "# Function to assemble job description text\n",
    "def assemble_jd(row):\n",
    "    parts = []\n",
    "    if pd.notna(row.get(\"job_position_name\")):\n",
    "        parts.append(\"Position: \" + row[\"job_position_name\"])\n",
    "    if pd.notna(row.get(\"skills_required\")):\n",
    "        parts.append(\"Required Skills: \" + row[\"skills_required\"])\n",
    "    if pd.notna(row.get(\"responsibilities.1\")):\n",
    "        parts.append(\"Responsibilities: \" + row[\"responsibilities.1\"])\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "# Convert to JSONL format\n",
    "with open(output_path, 'w', encoding='utf-8') as outfile:\n",
    "    for _, row in df.iterrows():\n",
    "        resume_text = assemble_resume(row)\n",
    "        jd_text = assemble_jd(row)\n",
    "        if resume_text.strip() and jd_text.strip():\n",
    "            data = {\n",
    "                \"prompt\": jd_text.strip() + \"\\n\\n Generate a resume:\",\n",
    "                \"completion\": \" \" + resume_text.strip()\n",
    "            }\n",
    "            json.dump(data, outfile, ensure_ascii=False)\n",
    "            outfile.write(\"\\n\")\n",
    "\n",
    "print(f\"Data successfully saved to {output_path}\")\n",
    "\n",
    "# Fine-Tuning GPT-2 using Hugging Face\n",
    "MODEL_NAME = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset('json', data_files=output_path, split='train')\n",
    "\n",
    "# Tokenize dataset\n",
    "def tokenize_function(examples):\n",
    "    full_texts = [p + \" \" + c for p, c in zip(examples['prompt'], examples['completion'])]\n",
    "    tokenized_output = tokenizer(full_texts, padding=\"max_length\", truncation=True, max_length=256)\n",
    "    return tokenized_output\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=8, \n",
    "    num_train_epochs=1,  \n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100, \n",
    "    save_steps=100,  \n",
    "    evaluation_strategy=\"no\",\n",
    "    warmup_steps=5,  \n",
    "    learning_rate=5e-5, \n",
    "    fp16=True,  \n",
    "    dataloader_num_workers=4 \n",
    ")\n",
    "\n",
    "# Load model\n",
    "model = GPT2LMHeadModel.from_pretrained(MODEL_NAME)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Custom Trainer Class\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        if \"labels\" not in inputs:\n",
    "            inputs[\"labels\"] = inputs[\"input_ids\"].clone()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            labels=inputs[\"labels\"]\n",
    "        )\n",
    "\n",
    "        # Loss\n",
    "        loss = outputs.loss\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# Instantiate Trainer\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer.train()\n",
    "\n",
    "print(\"Fine-tuning completed!\")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"./fine_tuned_model\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_model\")\n",
    "print(\"Model and tokenizer saved to ./fine_tuned_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bb9def-8a93-4c78-8811-389a10ae11a4",
   "metadata": {},
   "source": [
    "# 4. Generate modified Resume based on fine-tuned gpt model from above and generate a cover letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78539309-1de6-4f1c-8431-67a8ca63ceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "class LocalResumeGenerator:\n",
    "    def __init__(self, model_dir: str, device: str = 'cpu'):\n",
    "        \"\"\"\n",
    "        Initialize the generator with a fine-tuned GPT-2 model.\n",
    "\n",
    "        Args:\n",
    "            model_dir: Path to the directory containing the fine-tuned model.\n",
    "            device: 'cpu' or 'cuda'.\n",
    "        \"\"\"\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(model_dir)\n",
    "        self.model     = GPT2LMHeadModel.from_pretrained(model_dir).to(device)\n",
    "        self.device    = device\n",
    "\n",
    "        if self.tokenizer.pad_token_id is None:\n",
    "            self.tokenizer.pad_token_id = self.tokenizer.eos_token_id\n",
    "\n",
    "    def _generate(self, prompt: str, max_new_tokens: int = 200) -> str:\n",
    "        \"\"\"\n",
    "        Internal generation method using max_new_tokens while ensuring\n",
    "        total length never exceeds model's context window.\n",
    "        \"\"\"\n",
    "        max_window = self.tokenizer.model_max_length\n",
    "        max_prompt_len = max_window - max_new_tokens\n",
    "\n",
    "        inputs = self.tokenizer(\n",
    "            prompt,\n",
    "            return_tensors='pt',\n",
    "            truncation=True,\n",
    "            max_length=max_prompt_len\n",
    "        ).to(self.device)\n",
    "\n",
    "        output_ids = self.model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            pad_token_id=self.tokenizer.eos_token_id\n",
    "        )\n",
    "        return self.tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    def improve_resume(self, clean_text: str, jd: str) -> str:\n",
    "        \"\"\"\n",
    "        Rewrite the candidate's resume to align with the job description.\n",
    "        \"\"\"\n",
    "        system_prompt = (\n",
    "            \"You are a professional career coach specializing in risk management roles. \"\n",
    "            \"Rewrite the candidate’s resume to match the job description. \"\n",
    "            \"Output format:\\n\"\n",
    "            \"1. Professional Summary (1–2 sentences)\\n\"\n",
    "            \"2. Key Skills (bullet list, max 6 items)\\n\"\n",
    "            \"3. Experience (bullet list, focus on quantifiable achievements, max 5 items)\\n\"\n",
    "            \"4. Education (degree, institution, year)\\n\"\n",
    "            \"Use a concise, professional tone.\"\n",
    "        )\n",
    "        user_prompt = (\n",
    "            f\"{system_prompt}\\n\\n\"\n",
    "            f\"Original Resume:\\n{clean_text}\\n\\n\"\n",
    "            f\"Job Description:\\n{jd}\\n\\n\"\n",
    "            \"Rewritten Resume:\"\n",
    "        )\n",
    "        return self._generate(user_prompt)\n",
    "\n",
    "    def make_cover_letter(self, clean_text: str, jd: str) -> str:\n",
    "        \"\"\"\n",
    "        Generate a targeted cover letter based on the resume and job description.\n",
    "        \"\"\"\n",
    "        system_prompt = (\n",
    "            \"You are an expert cover letter writer for entry-level risk management positions. \"\n",
    "            \"Write a three-paragraph cover letter as follows:\\n\"\n",
    "            \"1. Opening paragraph: introduce the application motive, mention the job title and company name;\\n\"\n",
    "            \"2. Middle paragraph: highlight 2–3 most relevant experiences from the resume and explain how they prepare the candidate for this role;\\n\"\n",
    "            \"3. Closing paragraph: express enthusiasm for the opportunity and indicate next steps politely.\\n\"\n",
    "            \"Keep the total length between 250 and 300 words, in a professional and enthusiastic tone.\"\n",
    "        )\n",
    "        user_prompt = (\n",
    "            f\"{system_prompt}\\n\\n\"\n",
    "            f\"Resume:\\n{clean_text}\\n\\n\"\n",
    "            f\"Job Description:\\n{jd}\\n\\n\"\n",
    "            \"Cover Letter:\"\n",
    "        )\n",
    "        return self._generate(user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "765f494c-e669-4cdf-9b1a-38995133b336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Generated resume and cover letter are saved in the same file path under folder: data/final_outputs\n"
     ]
    }
   ],
   "source": [
    "gen = LocalResumeGenerator(\"./fine_tuned_model\")\n",
    "with open('data/processed/processed_resumes.json','r',encoding='utf-8') as f:\n",
    "    recs = json.load(f)\n",
    "\n",
    "for rec in recs:\n",
    "    imp = gen.improve_resume(rec['clean_text'], job_description)\n",
    "    cov = gen.make_cover_letter(rec['clean_text'], job_description)\n",
    "\n",
    "    out_dir = 'data/final_outputs_gpt2'\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    with open(f\"{out_dir}/{rec['id']}_resume.txt\", 'w', encoding='utf-8') as f:\n",
    "        f.write(imp)\n",
    "    with open(f\"{out_dir}/{rec['id']}_cover_letter.txt\", 'w', encoding='utf-8') as f:\n",
    "        f.write(cov)\n",
    "\n",
    "print(\"Done. Generated resume and cover letter are saved in the same file path under folder: data/final_outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32022242-927f-4e96-be23-27443c99dc8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
